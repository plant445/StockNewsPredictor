{
 "cells": [
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "import torch\n",
    "print(torch.version.cuda)\n",
    "\n",
    "\n",
    "if not torch.backends.mps.is_available():\n",
    "    if not torch.backends.mps.is_built():\n",
    "        print(\"MPS not available because the current PyTorch install was not \"\n",
    "              \"built with MPS enabled.\")\n",
    "    else:\n",
    "        print(\"MPS not available because the current MacOS version is not 12.3+ \"\n",
    "              \"and/or you do not have an MPS-enabled device on this machine.\")\n",
    "\n",
    "else:\n",
    "    mps_device = torch.device(\"mps\")\n",
    "print(f\"Using device: {mps_device}\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-24T23:58:58.726145Z",
     "start_time": "2024-11-24T23:58:58.597395Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "news_data = pd.read_csv(\"news.csv\")\n",
    "news_data = news_data.drop(['Date'], axis=1)\n",
    "# Combine Top1-Top25 into a single string\n",
    "news_data['combined_text'] = news_data.iloc[:, 1:].apply(lambda x: \" \".join(x.dropna()), axis=1)\n",
    "columns_2 = ['Top1','Top2','Top3', 'Top4', 'Top5','Top6', 'Top7', 'Top8', 'Top9', 'Top10', 'Top11', 'Top12', 'Top13', 'Top14', 'Top15', 'Top16', 'Top17', 'Top18', 'Top19', 'Top20', 'Top21', 'Top22', 'Top23','Top24', 'Top25']\n",
    "news_data = news_data.drop(columns_2, axis=1)\n",
    "news_data = news_data.replace('b\\\"|b\\'|\\\\\\\\|\\\\\\\"', '', regex=True)\n",
    "\n",
    "news_data.head()"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "   Label                                      combined_text\n",
       "0      0  Georgia 'downs two Russian warplanes' as count...\n",
       "1      1  Why wont America and Nato help us? If they won...\n",
       "2      0  Remember that adorable 9-year-old who sang at ...\n",
       "3      0   U.S. refuses Israel weapons to attack Iran: r...\n",
       "4      1  All the experts admit that we should legalise ..."
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>combined_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Georgia 'downs two Russian warplanes' as count...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Why wont America and Nato help us? If they won...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>Remember that adorable 9-year-old who sang at ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>U.S. refuses Israel weapons to attack Iran: r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>All the experts admit that we should legalise ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 22
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-25T00:07:17.002533Z",
     "start_time": "2024-11-25T00:07:16.999274Z"
    }
   },
   "source": [
    "from torch.utils.data import DataLoader, Dataset\n",
    "from transformers import BertTokenizer\n",
    "\n",
    "class TextDataset(Dataset):\n",
    "    def __init__(self, dataframe, max_length=512, tokenizer_name='bert-base-uncased'):\n",
    "        self.texts = dataframe['combined_text'].values\n",
    "        self.targets = dataframe['Label'].values\n",
    "        self.tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "        self.max_length = max_length\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        text = self.texts[idx]\n",
    "        target = self.targets[idx]\n",
    "        encoding = self.tokenizer.encode_plus(\n",
    "            text,\n",
    "            add_special_tokens=True,\n",
    "            max_length=self.max_length,\n",
    "            padding='max_length',\n",
    "            truncation=True,\n",
    "            return_attention_mask=True,\n",
    "            return_tensors='pt'\n",
    "        )\n",
    "        input_ids = encoding['input_ids'].flatten()\n",
    "        attention_mask = encoding['attention_mask'].flatten()\n",
    "        \n",
    "        return {\n",
    "            'input_ids': torch.as_tensor(input_ids, dtype=torch.long),\n",
    "            'attention_mask': torch.as_tensor(attention_mask, dtype=torch.long),\n",
    "            'targets': torch.as_tensor(target, dtype=torch.long),\n",
    "            'text': text\n",
    "        }"
   ],
   "outputs": [],
   "execution_count": 34
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train_data, test_data = train_test_split(news_data, train_size=0.9, shuffle=True, random_state=1702)\n",
    "print('{:>5,} Training samples'.format(len(train_data)))\n",
    "print('{:>5,} Validation samples'.format(len(test_data)))\n",
    "# Create custom Datasets\n",
    "train_dataset = TextDataset(train_data)\n",
    "test_dataset = TextDataset(test_data)\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "BATCH_SIZE = 16\n",
    "\n",
    "torch.manual_seed(1702)\n",
    "train_loader = DataLoader(train_dataset, \n",
    "                          batch_size=BATCH_SIZE,\n",
    "                          shuffle=True)\n",
    "test_loader = DataLoader(test_dataset,\n",
    "                         batch_size=len(test_dataset))\n",
    "next(iter(train_loader))"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "#from torch import cuda\n",
    "#torch.cuda.empty_cache()\n",
    "device = 'mps'\n",
    "\n",
    "from transformers import BertForSequenceClassification, AdamW, BertConfig\n",
    "\n",
    "model = BertForSequenceClassification.from_pretrained(\n",
    "    \"bert-base-uncased\",\n",
    "    num_labels = 2,\n",
    "    output_attentions = False,\n",
    "    output_hidden_states = False,\n",
    ")\n",
    "\n",
    "model.to(device)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-25T00:49:07.084227Z",
     "start_time": "2024-11-25T00:20:52.421553Z"
    }
   },
   "cell_type": "code",
   "source": [
    "EPOCHS = 5\n",
    "\n",
    "optimizer = torch.optim.AdamW(model.parameters(),\n",
    "                  lr = 2e-5, \n",
    "                  eps = 1e-8)\n",
    "import time\n",
    "import datetime\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
    "\n",
    "training_stats = []\n",
    "epoch_loss_train = []\n",
    "total_t0 = time.time()\n",
    "\n",
    "# TRAINING\n",
    "for epoch in range(1, EPOCHS + 1):\n",
    "    model.train()\n",
    "    t0 = time.time()\n",
    "    print(\"\")\n",
    "    print(\"================ Epoch {:} / {:} ================\".format(epoch, EPOCHS))\n",
    "    train_all_predictions = []\n",
    "    train_all_true_labels = []\n",
    "    for step, data in enumerate(train_loader):\n",
    "        if step % 2 == 0 and not step == 0:\n",
    "            elapsed = int(round(time.time() - t0))\n",
    "            elapsed = str(datetime.timedelta(seconds=elapsed))\n",
    "            print(\n",
    "                \"  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.\".format(\n",
    "                    step, len(train_loader), elapsed\n",
    "                )\n",
    "            )\n",
    "\n",
    "        targets = data[\"targets\"].to(device)\n",
    "        mask = data[\"attention_mask\"].to(device)\n",
    "        ids = data[\"input_ids\"].to(device)\n",
    "\n",
    "        model.zero_grad()\n",
    "\n",
    "        loss, logits = model(\n",
    "            ids, token_type_ids=None, attention_mask=mask, labels=targets\n",
    "        ).to_tuple()\n",
    "        epoch_loss_train.append(loss.item())\n",
    "\n",
    "        cpu_logits = logits.cpu().detach().numpy()\n",
    "        train_all_predictions.extend(np.argmax(cpu_logits, axis=1).flatten())\n",
    "        train_all_true_labels.extend(targets.cpu().numpy())\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    train_accuracy = accuracy_score(train_all_true_labels, train_all_predictions)\n",
    "    train_precision, train_recall, train_f1, _ = precision_recall_fscore_support(\n",
    "        train_all_true_labels, train_all_predictions, average=\"binary\"\n",
    "    )\n",
    "    print(\"\")\n",
    "    print('---TRAIN METRICS---')\n",
    "    print(f\"Loss: {np.mean(epoch_loss_train):.4f}\")\n",
    "    print(f\"Accuracy: {train_accuracy:.4f}\")\n",
    "    print(f\"Precision: {train_precision:.4f}\")\n",
    "    print(f\"Recall: {train_recall:.4f}\")\n",
    "    print(f\"F1-Score: {train_f1:.4f}\")\n",
    "    print(\"\")\n",
    "    \n",
    "    # VALIDATION\n",
    "    # print(\"Running validation ...\")\n",
    "    # print(\"\")\n",
    "    # model.eval()\n",
    "    # epoch_loss_test = []\n",
    "    # test_all_predictions = []\n",
    "    # test_all_true_labels = []\n",
    "    # for data in test_loader:\n",
    "    #     targets = data[\"targets\"].to(device)\n",
    "    #     mask = data[\"attention_mask\"].to(device)\n",
    "    #     ids = data[\"input_ids\"].to(device)\n",
    "    #     \n",
    "    #     with torch.no_grad():\n",
    "    #         loss, logits = model(ids, token_type_ids=None, attention_mask=mask, labels=targets).to_tuple()\n",
    "    #         \n",
    "    #     epoch_loss_test.append(loss.item())\n",
    "    #     cpu_logits = logits.cpu().detach().numpy()\n",
    "    #     test_all_predictions.extend(np.argmax(cpu_logits, axis=1).flatten())\n",
    "    #     test_all_true_labels.extend(targets.cpu().numpy())\n",
    "    # test_accuracy = accuracy_score(test_all_true_labels, test_all_predictions)\n",
    "    # test_precision, test_recall, test_f1, _ = precision_recall_fscore_support(\n",
    "    #     test_all_true_labels, test_all_predictions, average=\"binary\"\n",
    "    # )\n",
    "    # print(\"\")\n",
    "    # print('---TEST METRICS---')\n",
    "    # print(f\"Loss: {np.mean(epoch_loss_test):.4f}\")\n",
    "    # print(f\"Accuracy: {test_accuracy:.4f}\")\n",
    "    # print(f\"Precision: {test_precision:.4f}\")\n",
    "    # print(f\"Recall: {test_recall:.4f}\")\n",
    "    # print(f\"F1-Score: {test_f1:.4f}\")\n",
    "    # \n",
    "    # training_stats.append(\n",
    "    #         {\n",
    "    #         'epoch': epoch,\n",
    "    #         'Training Loss': np.mean(epoch_loss_train),\n",
    "    #         'Training Accuracy': train_accuracy,\n",
    "    #         'Training Precision': train_precision,\n",
    "    #         'Training Recall': train_recall,\n",
    "    #         'Training F1': train_f1,\n",
    "    #         'Validation Loss': np.mean(epoch_loss_test),\n",
    "    #         'Validation Accuracy': test_accuracy,\n",
    "    #         'Validation Precision': test_precision,\n",
    "    #         'Validation Recall': test_recall,\n",
    "    #         'Validation F1': test_f1\n",
    "    #     }\n",
    "    # )"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================ Epoch 1 / 5 ================\n",
      "  Batch     2  of    112.    Elapsed: 0:00:37.\n",
      "  Batch     4  of    112.    Elapsed: 0:01:20.\n",
      "  Batch     6  of    112.    Elapsed: 0:01:58.\n",
      "  Batch     8  of    112.    Elapsed: 0:02:33.\n",
      "  Batch    10  of    112.    Elapsed: 0:03:07.\n",
      "  Batch    12  of    112.    Elapsed: 0:03:38.\n",
      "  Batch    14  of    112.    Elapsed: 0:04:08.\n",
      "  Batch    16  of    112.    Elapsed: 0:04:40.\n",
      "  Batch    18  of    112.    Elapsed: 0:05:10.\n",
      "  Batch    20  of    112.    Elapsed: 0:05:38.\n",
      "  Batch    22  of    112.    Elapsed: 0:06:07.\n",
      "  Batch    24  of    112.    Elapsed: 0:06:36.\n",
      "  Batch    26  of    112.    Elapsed: 0:07:06.\n",
      "  Batch    28  of    112.    Elapsed: 0:07:42.\n",
      "  Batch    30  of    112.    Elapsed: 0:08:16.\n",
      "  Batch    32  of    112.    Elapsed: 0:08:47.\n",
      "  Batch    34  of    112.    Elapsed: 0:09:14.\n",
      "  Batch    36  of    112.    Elapsed: 0:09:41.\n",
      "  Batch    38  of    112.    Elapsed: 0:10:08.\n",
      "  Batch    40  of    112.    Elapsed: 0:10:34.\n",
      "  Batch    42  of    112.    Elapsed: 0:11:03.\n",
      "  Batch    44  of    112.    Elapsed: 0:11:31.\n",
      "  Batch    46  of    112.    Elapsed: 0:11:59.\n",
      "  Batch    48  of    112.    Elapsed: 0:12:26.\n",
      "  Batch    50  of    112.    Elapsed: 0:12:53.\n",
      "  Batch    52  of    112.    Elapsed: 0:13:22.\n",
      "  Batch    54  of    112.    Elapsed: 0:13:52.\n",
      "  Batch    56  of    112.    Elapsed: 0:14:20.\n",
      "  Batch    58  of    112.    Elapsed: 0:14:47.\n",
      "  Batch    60  of    112.    Elapsed: 0:15:14.\n",
      "  Batch    62  of    112.    Elapsed: 0:15:41.\n",
      "  Batch    64  of    112.    Elapsed: 0:16:10.\n",
      "  Batch    66  of    112.    Elapsed: 0:16:37.\n",
      "  Batch    68  of    112.    Elapsed: 0:17:03.\n",
      "  Batch    70  of    112.    Elapsed: 0:17:31.\n",
      "  Batch    72  of    112.    Elapsed: 0:18:04.\n",
      "  Batch    74  of    112.    Elapsed: 0:18:33.\n",
      "  Batch    76  of    112.    Elapsed: 0:19:01.\n",
      "  Batch    78  of    112.    Elapsed: 0:19:29.\n",
      "  Batch    80  of    112.    Elapsed: 0:19:57.\n",
      "  Batch    82  of    112.    Elapsed: 0:20:23.\n",
      "  Batch    84  of    112.    Elapsed: 0:20:50.\n",
      "  Batch    86  of    112.    Elapsed: 0:21:17.\n",
      "  Batch    88  of    112.    Elapsed: 0:21:54.\n",
      "  Batch    90  of    112.    Elapsed: 0:22:23.\n",
      "  Batch    92  of    112.    Elapsed: 0:22:52.\n",
      "  Batch    94  of    112.    Elapsed: 0:23:20.\n",
      "  Batch    96  of    112.    Elapsed: 0:23:47.\n",
      "  Batch    98  of    112.    Elapsed: 0:24:14.\n",
      "  Batch   100  of    112.    Elapsed: 0:24:42.\n",
      "  Batch   102  of    112.    Elapsed: 0:25:09.\n",
      "  Batch   104  of    112.    Elapsed: 0:25:36.\n",
      "  Batch   106  of    112.    Elapsed: 0:26:03.\n",
      "  Batch   108  of    112.    Elapsed: 0:26:28.\n",
      "  Batch   110  of    112.    Elapsed: 0:27:01.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "---TRAIN METRICS---\n",
      "Loss: nan\n",
      "Accuracy: 0.4721\n",
      "Precision: 0.0000\n",
      "Recall: 0.0000\n",
      "F1-Score: 0.0000\n",
      "\n",
      "\n",
      "================ Epoch 2 / 5 ================\n",
      "  Batch     2  of    112.    Elapsed: 0:00:30.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "execution_count": 40
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlteam",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
